---
layout: post
title:  "24-05 1주 TwIL"
categories: [TwIL]
tags: [Infra]
---

## 들어가며
이번주에는 AWS DMS 설정 부분을 기록하려고 합니다.

## 데이터 변경 이력 저장
회사에서 데이터가 변경되었을 때의 이력을 추적하기 위한 작업을 시작했습니다. 
"혹시 이 데이터 언제 삭제되었죠?"에 대한 답을 마련하기 위한, 그리고 향후 데이터 분석에 기반 작업이라고 보시면 될거 같습니다.

[AWS DMS(Database Migration Service)](https://aws.amazon.com/ko/dms/)와 [Apache Airflow](https://airflow.apache.org)를 이용해서 구현해보려고 합니다.
DMS 는 간단하게 말하면, 데이터를 한 시스템에서 다른 시스템으로 이동, 마이그레이션 시키는 서비스라고 보시면 될거 같아요. 
데이터의 흐름은 아래를 참고해주세요. DMS 가 RDS 의 변경이력 데이터를 S3 에 적재하고, Airflow 가 S3의 데이터를 읽어서 BigQuery 에 적재하는 방식으로 하려고 합니다.

![](/assets/img/post2-1.png){: width="400" }

(좀 어려워보이네요... 파이팅)

### PostgreSQL 에서 PK 변경하기
DMS 작업에 앞서 어떤 Row 가 변경되었지를 판단할 때 기준이 되는 id 컬럼을 모든 테이블에 추가해주는 작업을 선행 했습니다.
대부분의 테이블에 ID 가 당연하게 있었지만 Association 테이블이나 특정한 이유로 ID를 복합키를 사용하고 있던 테이블은 id가 없었기 때문에 PK 를 수정해주어야 했어요.

두가지 방법을 고려하고 있었는데.
1. PK 를 변경하려는 테이블과 똑같은 컬럼과 변경된 PK 로 테이블을 하나 더 생성한 후, 데이터를 모두 마이그레이션 하고 기존 테이블 삭제 후 새로운 테이블의 네이밍을 변경한다.
2. (된다면) PK 만 변경한다.

작업자 입장에서 당연히 2번이 하고 싶었습니다. PK 를 변경하려는 테이블을 모두 마이그레이션 한다는건 참 위험해보이지 않나요..?

결론부터 이야기 하자면 PostgreSQL 에서 다행히도 PK 만 변경할 수 있는 방법이 있었어요! 변경이라기엔 삭제하고 추가해주는 형식이지만요.
```sql
ALTER TABLE {table_name} DROP CONSTRAINT {pk_name};
ALTER TABLE {table_name} ADD CONSTRAINT {table_name}_pk PRIMARY KEY (id);

ALTER TABLE {table_name} ADD CONSTRAINT {table_name}_unique_key UNIQUE ({column1, column2});
```
추가적으로 기존에 있던 복합키 id 들로 unique 도 걸어주었어요.

drop 했을 때 오류가 나지 않을까 우려했었는데 psql 이 착하게도 허용해주네요ㅎㅎ 덕분에 비교적 간단하게 선행 작업을 할 수 있었어요.

### DMS 설정하기
회사에서 인프라 관련 설정들은 Terraform 코드로 관리하고 있습니다. DMS 또한 Terraform 코드를 통해 apply 했어요.

task 를 생성해보는 걸 목표로 잡았습니다.

(예시)
```terraform
resource "aws_dms_replication_task" "cdc_task" {
  migration_type           = "cdc"
  replication_instance_arn = aws_dms_replication_instance.{instance}.replication_instance_arn
  replication_task_id      = "cdc_task"
  source_endpoint_arn      = aws_dms_endpoint.{source_endpoint}.endpoint_arn
  target_endpoint_arn      = aws_dms_s3_endpoint.{target_endpoint}.endpoint_arn
  replication_task_settings = // 생략

  table_mappings = jsonencode({
    "rules" : [
      {
        "rule-type" : "selection",
        "rule-id" : "1",
        "rule-name" : "1",
        "object-locator" : { "schema-name" : "%", "table-name" : "%" }, "rule-action" : "include"
      },
      
      {
        "rule-type" : "selection",
        "rule-id" : "2",
        "rule-name" : "exclude-test-tables",
        "object-locator" : { "schema-name" : "%", "table-name" : "test_%" },
        "rule-action" : "exclude"
      },
    ]
  })
}
```

migration_type
: 변경사항에 대해서만 저장할거라 `full-load | cdc | full-load-and-cdc` 중 cdc(지속적 복제(변경 데이터 캡처))[^cdc] 를 넣어줍니다. `full-load` 와 `full-load-and-cdc` 는 각각 기존 데이터 마이그레이션(전체 로드), 캐시된 변경 사항 적용을 나타냅니다.  

replication_instance_arn
: dms instance arn 입니다. 위 resource 는 instance 가 아닌 task 임을 확인해주세요.

source_endpoint_arn
: dms 에서 복제할 source 의 end point arn 입니다. ex) RDS 의 arn

target_endpoint_arn
: source 의 변경사항을 입력할 target end point arn 입니다. ex) S3 의 arn

table_mappings
: 특정 테이블에 대한 변경사항만 감지하고 싶을 땐 위처럼 설정해주면 됩니다. 

그외 인스턴스 설정과 endpoint 들에 대한 resource 생성과 policy 에 s3 저장소를 열어주는 등의 추가 설정이 필요할 수 있어요.

추가 설정 후 apply 하면..!!!!
실패했지요...ㅎㅎ

![](/assets/img/post2-3.png){: width="400" }

![](/assets/img/post2-2.jpeg){: width="100" } 


PostgreSQL 에서도 관련 설정이 필요합니다. 그 설정들은 다음주에 다뤄보겠습니다. (실패로 글을 마무리 하다니.)

## 마치며
인프라 쪽 경험이 많이 없어서 부정확한 내용이 있을 수 있는 점 참고해주세요. 인프라 꽤 재밌네요. 가끔하면 좋을거 같아요^^
관련 도움주신 회사분께 아주 감사한 마음입니다^^(보고 계실 수 있으니)

다음주에는 바로 위에서 언급한 PostgreSQL 관련 설정과 cdc 저장 데이터 중 commit time 을 추가하는 작업을 할 예정이에요.

---
[^cdc]: CDC(Change Data Capture, 변경 데이터 캡처)는 데이터베이스에서 발생하는 데이터 변경 사항(삽입, 업데이트, 삭제)을 실시간 또는 거의 실시간으로 추적하고 캡처하는 기술입니다. CDC는 데이터베이스 시스템 간의 데이터 동기화, 데이터 웨어하우스 업데이트, 데이터 통합, 이벤트 기반 아키텍처 등에서 중요한 역할을 합니다.(from.Chat GPT 형님)
